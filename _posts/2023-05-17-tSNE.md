# What is T-SNE, and how do you say it?
I am not sure how to say, currently just pronoucning the letters as it is an acronym and not its own word. 
t-SNE stands for t-Distributed Stochastic Neighbor Embedding. Sounds quite complicated but I will try to explain what it is and how it is applied to machine learning. 

## An Introduction to Dimensionality Reduction for Machine Learning

In the realm of machine learning, dimensionality reduction techniques play a vital role in transforming high-dimensional data into a more manageable and visually interpretable representation. 
One such technique that has gained significant popularity is t-SNE (t-Distributed Stochastic Neighbor Embedding). 
In this blog post, we will explore what t-SNE means, how it is used, and why it is important for machine learning tasks.

## What is t-SNE?
t-SNE is a nonlinear dimensionality reduction technique used to visualize and explore high-dimensional data. 
It was introduced by Laurens van der Maaten and Geoffrey Hinton in 2008. 
Unlike linear techniques like Principal Component Analysis (PCA), t-SNE aims to preserve the local and global structure of the data by capturing nonlinear relationships.<br>
And to put it simply, t-SNE can give us a intuition into how the data is arranged in a high-dimensional space. t-SNE plots can often be very colourful and to the untrained eye cool patterns or random, but as we learn more about them we will understand the power of a t-SNE plot.
An example is presented below.

<img
  src="/images/t-sne.png"
  style="display: inline-block; margin: 0 auto; max-width: 250px">

## How does t-SNE work?
t-SNE reduces the dimensionality of data while attempting to preserve the similarity relationships between data points. 
It constructs a probability distribution over pairs of high-dimensional points, aiming to make similar points have a higher probability of being chosen. 
Simultaneously, it constructs a similar probability distribution over the lower-dimensional embedding space, aiming to make pairs of points have similar probabilities. 
The technique iteratively optimizes these probability distributions to find a low-dimensional representation of the data where similar points are mapped close to each other.

## Visualization and Exploratory Data Analysis:
One of the primary applications of t-SNE is in data visualization. By reducing the dimensionality of data, t-SNE allows us to plot high-dimensional data in two or three dimensions, enabling visual exploration and analysis. 
It helps in identifying clusters, patterns, and outliers that may not be apparent in the original high-dimensional space. 
Visualization using t-SNE aids in gaining insights, understanding data structures, and formulating hypotheses.

## Understanding Data Relationships:
t-SNE is effective in revealing complex relationships and structures within the data. It can expose non-linear patterns, identify local neighborhoods, and highlight data points with similar attributes. 
By visualizing the embedding generated by t-SNE, we can identify groups or clusters of similar instances, understand class separability, and observe the relative distances between different data points.

## Preprocessing and Feature Engineering:
t-SNE can be employed as a tool for feature engineering and data preprocessing. It can assist in identifying relevant features or subsets of features that contribute significantly to the separation or grouping of instances. 
By visualizing the t-SNE representation of the data, we can identify informative features and reduce the dimensionality of the input space, leading to improved model performance and efficiency. The website I am currently following to make adjustments to the hyperparameters is as [t-SNE adjustment]([https://www.markdownguide.org/basic-syntax/#lists-1](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)).

## Model Evaluation and Validation:
t-SNE can be utilized for model evaluation and validation purposes. By visualizing the embeddings of both the training and test datasets, we can assess the generalization capability of the model. 
If the model successfully captures the underlying structure and relationships in the data, we would expect to see similar patterns and clusters in both the training and test embeddings.

t-SNE is a powerful technique for dimensionality reduction and data visualization in machine learning. 
It enables us to explore and interpret high-dimensional data, revealing intricate structures and relationships. By visualizing data in a lower-dimensional space, t-SNE aids in gaining insights, identifying clusters, and formulating hypotheses. 
It serves as a valuable tool for preprocessing, feature engineering, and model evaluation. Incorporating t-SNE into the machine learning pipeline can enhance our understanding of data, improve model performance, and facilitate decision-making in various domains.

As the field of machine learning continues to advance, t-SNE will remain a fundamental technique for visual exploration and analysis of complex datasets, providing valuable insights into the underlying patterns and structures within high-dimensional data.

## Applying t-SNE to my computer vision problem. 
One task in our assignment is to tweak a pre-trained machine learning model vision_learer to classify real and fake images. After tweaking the model and achieving 95.78% I wanted to understand the high dimension data set better. One of the generated t-SNE plots from my analysis is as shown below:

<img
  src="/images/t-sne Q3.png"
  style="display: inline-block; margin: 0 auto; max-width: 250px">
  
The hyperparameters need to be adjusted to get the data to cluster together rather than snake out as it is. This will take some time to adjust the parameters. 
The website I am following to make adjustments to the t-SNE plot's hyperparameters is [sklearn.manifold.tsne](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html).
